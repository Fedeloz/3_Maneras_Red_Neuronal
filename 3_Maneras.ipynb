{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_Maneras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pODB-0JOFJR",
        "colab_type": "text"
      },
      "source": [
        "### 3 Maneras de programar una red Neuronal\n",
        "\n",
        "## Código inicial:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZKMct2lEnz5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "a8012d43-eb89-478e-81a3-94293cc1d6a4"
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_circles\n",
        "\n",
        "# Creamos nuestros datos artificiales, donde buscaremos clasificar \n",
        "# dos anillos concéntricos de datos. \n",
        "X, Y = make_circles(n_samples=500, factor=0.5, noise=0.05)\n",
        "\n",
        "# Resolución del mapa de predicción.\n",
        "res = 100 \n",
        "\n",
        "# Coordendadas del mapa de predicción.\n",
        "_x0 = np.linspace(-1.5, 1.5, res)\n",
        "_x1 = np.linspace(-1.5, 1.5, res)\n",
        "\n",
        "# Input con cada combo de coordenadas del mapa de predicción.\n",
        "_pX = np.array(np.meshgrid(_x0, _x1)).T.reshape(-1, 2)\n",
        "\n",
        "# Objeto vacio a 0.5 del mapa de predicción.\n",
        "_pY = np.zeros((res, res)) + 0.5\n",
        "\n",
        "# Visualización del mapa de predicción.\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pcolormesh(_x0, _x1, _pY, cmap=\"coolwarm\", vmin=0, vmax=1)\n",
        "\n",
        "# Visualización de la nube de datos.\n",
        "plt.scatter(X[Y == 0,0], X[Y == 0,1], c=\"skyblue\")\n",
        "plt.scatter(X[Y == 1,0], X[Y == 1,1], c=\"salmon\")\n",
        "\n",
        "plt.tick_params(labelbottom=False, labelleft=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27e5KiF8NksQ",
        "colab_type": "text"
      },
      "source": [
        "## Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4R-y55iJlAy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "b8d39ace-6eaa-4a40-c2b7-c4ddd8c38e0d"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib import animation\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "# Definimos los puntos de entrada de la red, para la matriz X e Y.\n",
        "iX = tf.placeholder('float', shape=[None, X.shape[1]])\n",
        "iY = tf.placeholder('float', shape=[None])\n",
        "\n",
        "lr = 0.01           # learning rate\n",
        "nn = [2, 16, 8, 1]  # número de neuronas por capa.\n",
        "\n",
        "# Capa 1\n",
        "W1 = tf.Variable(tf.random_normal([nn[0], nn[1]]), name='Weights_1')\n",
        "b1 = tf.Variable(tf.random_normal([nn[1]]), name='bias_1')\n",
        "\n",
        "l1 = tf.nn.relu(tf.add(tf.matmul(iX, W1), b1))\n",
        "\n",
        "# Capa 2\n",
        "W2 = tf.Variable(tf.random_normal([nn[1], nn[2]]), name='Weights_2')\n",
        "b2 = tf.Variable(tf.random_normal([nn[2]]), name='bias_2')\n",
        "\n",
        "l2 = tf.nn.relu(tf.add(tf.matmul(l1, W2), b2))\n",
        "\n",
        "# Capa 3\n",
        "W3 = tf.Variable(tf.random_normal([nn[2], nn[3]]), name='Weights_3')\n",
        "b3 = tf.Variable(tf.random_normal([nn[3]]), name='bias_3')\n",
        "\n",
        "# Vector de predicciones de Y.\n",
        "pY = tf.nn.sigmoid(tf.add(tf.matmul(l2, W3), b3))[:, 0]\n",
        "\n",
        "\n",
        "# Evaluación de las predicciones.\n",
        "loss = tf.losses.mean_squared_error(pY, iY)\n",
        "\n",
        "# Definimos al optimizador de la red, para que minimice el error.\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(loss)\n",
        "\n",
        "n_steps = 1000 # Número de ciclos de entrenamiento.\n",
        "\n",
        "iPY = [] # Aquí guardaremos la evolución de las predicción, para la animación.\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  \n",
        "  # Inicializamos todos los parámetros de la red, las matrices W y b.\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "  # Iteramos n pases de entrenamiento.\n",
        "  for step in range(n_steps):\n",
        "  \n",
        "    # Evaluamos al optimizador, a la función de coste y al tensor de salida pY. \n",
        "    # La evaluación del optimizer producirá el entrenamiento de la red.\n",
        "    _, _loss, _pY = sess.run([optimizer, loss, pY], feed_dict={ iX : X, iY : Y })\n",
        "    \n",
        "    # Cada 25 iteraciones, imprimimos métricas.\n",
        "    if step % 25 == 0: \n",
        "      \n",
        "      # Cálculo del accuracy.\n",
        "      acc = np.mean(np.round(_pY) == Y)\n",
        "      \n",
        "      # Impresión de métricas.\n",
        "      print('Step', step, '/', n_steps, '- Loss = ', _loss, '- Acc =', acc)\n",
        "      \n",
        "      # Obtenemos predicciones para cada punto de nuestro mapa de predicción _pX.\n",
        "      _pY = sess.run(pY, feed_dict={ iX : _pX }).reshape((res, res))\n",
        "\n",
        "      # Y lo guardamos para visualizar la animación.\n",
        "      iPY.append(_pY)\n",
        "      \n",
        "  \n",
        "# ----- CÓDIGO ANIMACIÓN ----- #\n",
        "\n",
        "ims = []\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "print(\"--- Generando animación ---\")\n",
        "\n",
        "for fr in range(len(iPY)):\n",
        "  \n",
        "  im = plt.pcolormesh(_x0, _x1, iPY[fr], cmap=\"coolwarm\", animated=True)\n",
        "\n",
        "  # Visualización de la nube de datos.\n",
        "  plt.scatter(X[Y == 0,0], X[Y == 0,1], c=\"skyblue\")\n",
        "  plt.scatter(X[Y == 1,0], X[Y == 1,1], c=\"salmon\")\n",
        "\n",
        "  # plt.title(\"Resultado Clasificación\")\n",
        "  plt.tick_params(labelbottom=False, labelleft=False)\n",
        "\n",
        "  ims.append([im])\n",
        "\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)\n",
        "\n",
        "HTML(ani.to_html5_video())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0611342c2397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Definimos los puntos de entrada de la red, para la matriz X e Y.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0miX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0miY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmsBxHdeN6ri",
        "colab_type": "text"
      },
      "source": [
        "## Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3BNjSNhNX44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d3647170-749c-493a-9379-acdf67def5ba"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as kr\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "\n",
        "lr = 0.01           # learning rate\n",
        "nn = [2, 16, 8, 1]  # número de neuronas por capa.\n",
        "\n",
        "\n",
        "# Creamos el objeto que contendrá a nuestra red neuronal, como\n",
        "# secuencia de capas.\n",
        "model = kr.Sequential()\n",
        "\n",
        "# Añadimos la capa 1\n",
        "l1 = model.add(kr.layers.Dense(nn[1], activation='relu'))\n",
        "\n",
        "# Añadimos la capa 2\n",
        "l2 = model.add(kr.layers.Dense(nn[2], activation='relu'))\n",
        "\n",
        "# Añadimos la capa 3\n",
        "l3 = model.add(kr.layers.Dense(nn[3], activation='sigmoid'))\n",
        "\n",
        "# Compilamos el modelo, definiendo la función de coste y el optimizador.\n",
        "model.compile(loss='mse', optimizer=kr.optimizers.SGD(lr=0.05), metrics=['acc'])\n",
        "\n",
        "# Y entrenamos al modelo. Los callbacks \n",
        "model.fit(X, Y, epochs=100)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2590 - acc: 0.4720\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2566 - acc: 0.4680\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2546 - acc: 0.4600\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2529 - acc: 0.4360\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2513 - acc: 0.4380\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2499 - acc: 0.4240\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 985us/step - loss: 0.2485 - acc: 0.4500\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2473 - acc: 0.4940\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2461 - acc: 0.4920\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2450 - acc: 0.4980\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2438 - acc: 0.5040\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2427 - acc: 0.5140\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2416 - acc: 0.5120\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2405 - acc: 0.5200\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2393 - acc: 0.5420\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2383 - acc: 0.5620\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2371 - acc: 0.5820\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2359 - acc: 0.6080\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2345 - acc: 0.6800\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2329 - acc: 0.7000\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2313 - acc: 0.7340\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2289 - acc: 0.7740\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2266 - acc: 0.7880\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2243 - acc: 0.8160\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2222 - acc: 0.8160\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2202 - acc: 0.8120\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2182 - acc: 0.8260\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2162 - acc: 0.8280\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2141 - acc: 0.8280\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2116 - acc: 0.8460\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2091 - acc: 0.8660\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2066 - acc: 0.8680\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2041 - acc: 0.8760\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.2015 - acc: 0.8780\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1988 - acc: 0.8760\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1959 - acc: 0.8840\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1929 - acc: 0.8940\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1895 - acc: 0.9020\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1862 - acc: 0.9040\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1828 - acc: 0.9040\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1793 - acc: 0.9080\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1759 - acc: 0.9080\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1725 - acc: 0.9160\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1689 - acc: 0.9160\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1651 - acc: 0.9240\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1613 - acc: 0.9240\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1574 - acc: 0.9300\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1533 - acc: 0.9340\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1492 - acc: 0.9500\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1452 - acc: 0.9560\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1407 - acc: 0.9620\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1361 - acc: 0.9720\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1316 - acc: 0.9800\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1270 - acc: 0.9860\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1223 - acc: 0.9920\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1178 - acc: 0.9900\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1130 - acc: 0.9940\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1083 - acc: 0.9960\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1036 - acc: 1.0000\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0988 - acc: 1.0000\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0941 - acc: 1.0000\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0897 - acc: 1.0000\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0853 - acc: 1.0000\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0811 - acc: 1.0000\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0771 - acc: 1.0000\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0733 - acc: 1.0000\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0696 - acc: 1.0000\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0661 - acc: 1.0000\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0627 - acc: 1.0000\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0596 - acc: 1.0000\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0566 - acc: 1.0000\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0537 - acc: 1.0000\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0511 - acc: 1.0000\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0485 - acc: 1.0000\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0461 - acc: 1.0000\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0438 - acc: 1.0000\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 960us/step - loss: 0.0417 - acc: 1.0000\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0397 - acc: 1.0000\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0379 - acc: 1.0000\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0361 - acc: 1.0000\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0345 - acc: 1.0000\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0330 - acc: 1.0000\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0315 - acc: 1.0000\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0301 - acc: 1.0000\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0288 - acc: 1.0000\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0276 - acc: 1.0000\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0265 - acc: 1.0000\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0254 - acc: 1.0000\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0243 - acc: 1.0000\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0234 - acc: 1.0000\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0225 - acc: 1.0000\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0216 - acc: 1.0000\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0208 - acc: 1.0000\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0201 - acc: 1.0000\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0194 - acc: 1.0000\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0187 - acc: 1.0000\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0180 - acc: 1.0000\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0174 - acc: 1.0000\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0168 - acc: 1.0000\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.0163 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6c8f138748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPnppbnmOU1b",
        "colab_type": "text"
      },
      "source": [
        "## Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HMD4Pw9OW7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bm8XuL_Jq1S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e595f9f3-ab03-4bb4-f9e2-ce680c942069"
      },
      "source": [
        "import sklearn as sk\n",
        "import sklearn.neural_network\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "\n",
        "lr = 0.01           # learning rate\n",
        "nn = [2, 16, 8, 1]  # número de neuronas por capa.\n",
        "\n",
        "# Creamos el objeto del modelo de red neuronal multicapa.\n",
        "clf = sk.neural_network.MLPRegressor(solver='sgd', \n",
        "                                     learning_rate_init=lr, \n",
        "                                     hidden_layer_sizes=tuple(nn[1:]),\n",
        "                                     verbose=True,\n",
        "                                     n_iter_no_change=1000,\n",
        "                                     batch_size = 64)\n",
        "\n",
        "\n",
        "# Y lo entrenamos con nuestro datos.\n",
        "clf.fit(X, Y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53059391\n",
            "Iteration 2, loss = 0.16555056\n",
            "Iteration 3, loss = 0.11894367\n",
            "Iteration 4, loss = 0.11239453\n",
            "Iteration 5, loss = 0.10094165\n",
            "Iteration 6, loss = 0.09696660\n",
            "Iteration 7, loss = 0.09160345\n",
            "Iteration 8, loss = 0.08659005\n",
            "Iteration 9, loss = 0.08122251\n",
            "Iteration 10, loss = 0.07575577\n",
            "Iteration 11, loss = 0.07007582\n",
            "Iteration 12, loss = 0.06438630\n",
            "Iteration 13, loss = 0.05869248\n",
            "Iteration 14, loss = 0.05246615\n",
            "Iteration 15, loss = 0.04652806\n",
            "Iteration 16, loss = 0.04032890\n",
            "Iteration 17, loss = 0.03456690\n",
            "Iteration 18, loss = 0.02900434\n",
            "Iteration 19, loss = 0.02389088\n",
            "Iteration 20, loss = 0.01968953\n",
            "Iteration 21, loss = 0.01618530\n",
            "Iteration 22, loss = 0.01357058\n",
            "Iteration 23, loss = 0.01163013\n",
            "Iteration 24, loss = 0.01037060\n",
            "Iteration 25, loss = 0.00933589\n",
            "Iteration 26, loss = 0.00874497\n",
            "Iteration 27, loss = 0.00838185\n",
            "Iteration 28, loss = 0.00786584\n",
            "Iteration 29, loss = 0.00759146\n",
            "Iteration 30, loss = 0.00731467\n",
            "Iteration 31, loss = 0.00711036\n",
            "Iteration 32, loss = 0.00692128\n",
            "Iteration 33, loss = 0.00677212\n",
            "Iteration 34, loss = 0.00657453\n",
            "Iteration 35, loss = 0.00643200\n",
            "Iteration 36, loss = 0.00629644\n",
            "Iteration 37, loss = 0.00621287\n",
            "Iteration 38, loss = 0.00605416\n",
            "Iteration 39, loss = 0.00593271\n",
            "Iteration 40, loss = 0.00581442\n",
            "Iteration 41, loss = 0.00574103\n",
            "Iteration 42, loss = 0.00564320\n",
            "Iteration 43, loss = 0.00559628\n",
            "Iteration 44, loss = 0.00550701\n",
            "Iteration 45, loss = 0.00541749\n",
            "Iteration 46, loss = 0.00536575\n",
            "Iteration 47, loss = 0.00530161\n",
            "Iteration 48, loss = 0.00525619\n",
            "Iteration 49, loss = 0.00522252\n",
            "Iteration 50, loss = 0.00516633\n",
            "Iteration 51, loss = 0.00512673\n",
            "Iteration 52, loss = 0.00511130\n",
            "Iteration 53, loss = 0.00502756\n",
            "Iteration 54, loss = 0.00504261\n",
            "Iteration 55, loss = 0.00500454\n",
            "Iteration 56, loss = 0.00495491\n",
            "Iteration 57, loss = 0.00491519\n",
            "Iteration 58, loss = 0.00492473\n",
            "Iteration 59, loss = 0.00485961\n",
            "Iteration 60, loss = 0.00485055\n",
            "Iteration 61, loss = 0.00485227\n",
            "Iteration 62, loss = 0.00481370\n",
            "Iteration 63, loss = 0.00480663\n",
            "Iteration 64, loss = 0.00473730\n",
            "Iteration 65, loss = 0.00474441\n",
            "Iteration 66, loss = 0.00472505\n",
            "Iteration 67, loss = 0.00470471\n",
            "Iteration 68, loss = 0.00468456\n",
            "Iteration 69, loss = 0.00466976\n",
            "Iteration 70, loss = 0.00463703\n",
            "Iteration 71, loss = 0.00463185\n",
            "Iteration 72, loss = 0.00463463\n",
            "Iteration 73, loss = 0.00464284\n",
            "Iteration 74, loss = 0.00460634\n",
            "Iteration 75, loss = 0.00457429\n",
            "Iteration 76, loss = 0.00457534\n",
            "Iteration 77, loss = 0.00459092\n",
            "Iteration 78, loss = 0.00454373\n",
            "Iteration 79, loss = 0.00456601\n",
            "Iteration 80, loss = 0.00452251\n",
            "Iteration 81, loss = 0.00451686\n",
            "Iteration 82, loss = 0.00449692\n",
            "Iteration 83, loss = 0.00450008\n",
            "Iteration 84, loss = 0.00447556\n",
            "Iteration 85, loss = 0.00445967\n",
            "Iteration 86, loss = 0.00448520\n",
            "Iteration 87, loss = 0.00445841\n",
            "Iteration 88, loss = 0.00447024\n",
            "Iteration 89, loss = 0.00444714\n",
            "Iteration 90, loss = 0.00441821\n",
            "Iteration 91, loss = 0.00440300\n",
            "Iteration 92, loss = 0.00442013\n",
            "Iteration 93, loss = 0.00439319\n",
            "Iteration 94, loss = 0.00440049\n",
            "Iteration 95, loss = 0.00435334\n",
            "Iteration 96, loss = 0.00435925\n",
            "Iteration 97, loss = 0.00436474\n",
            "Iteration 98, loss = 0.00430998\n",
            "Iteration 99, loss = 0.00436641\n",
            "Iteration 100, loss = 0.00435544\n",
            "Iteration 101, loss = 0.00428898\n",
            "Iteration 102, loss = 0.00429687\n",
            "Iteration 103, loss = 0.00429183\n",
            "Iteration 104, loss = 0.00427752\n",
            "Iteration 105, loss = 0.00430426\n",
            "Iteration 106, loss = 0.00427238\n",
            "Iteration 107, loss = 0.00426605\n",
            "Iteration 108, loss = 0.00422530\n",
            "Iteration 109, loss = 0.00422060\n",
            "Iteration 110, loss = 0.00419349\n",
            "Iteration 111, loss = 0.00419334\n",
            "Iteration 112, loss = 0.00417777\n",
            "Iteration 113, loss = 0.00419590\n",
            "Iteration 114, loss = 0.00422523\n",
            "Iteration 115, loss = 0.00416179\n",
            "Iteration 116, loss = 0.00414597\n",
            "Iteration 117, loss = 0.00418378\n",
            "Iteration 118, loss = 0.00413715\n",
            "Iteration 119, loss = 0.00412212\n",
            "Iteration 120, loss = 0.00411555\n",
            "Iteration 121, loss = 0.00409695\n",
            "Iteration 122, loss = 0.00410663\n",
            "Iteration 123, loss = 0.00409164\n",
            "Iteration 124, loss = 0.00408059\n",
            "Iteration 125, loss = 0.00408780\n",
            "Iteration 126, loss = 0.00406159\n",
            "Iteration 127, loss = 0.00405486\n",
            "Iteration 128, loss = 0.00404632\n",
            "Iteration 129, loss = 0.00403536\n",
            "Iteration 130, loss = 0.00403229\n",
            "Iteration 131, loss = 0.00402510\n",
            "Iteration 132, loss = 0.00402236\n",
            "Iteration 133, loss = 0.00401285\n",
            "Iteration 134, loss = 0.00401189\n",
            "Iteration 135, loss = 0.00398302\n",
            "Iteration 136, loss = 0.00398901\n",
            "Iteration 137, loss = 0.00400156\n",
            "Iteration 138, loss = 0.00399451\n",
            "Iteration 139, loss = 0.00399084\n",
            "Iteration 140, loss = 0.00397304\n",
            "Iteration 141, loss = 0.00398364\n",
            "Iteration 142, loss = 0.00395500\n",
            "Iteration 143, loss = 0.00394878\n",
            "Iteration 144, loss = 0.00395820\n",
            "Iteration 145, loss = 0.00393019\n",
            "Iteration 146, loss = 0.00394636\n",
            "Iteration 147, loss = 0.00397104\n",
            "Iteration 148, loss = 0.00392196\n",
            "Iteration 149, loss = 0.00390479\n",
            "Iteration 150, loss = 0.00390682\n",
            "Iteration 151, loss = 0.00391229\n",
            "Iteration 152, loss = 0.00387813\n",
            "Iteration 153, loss = 0.00390250\n",
            "Iteration 154, loss = 0.00387615\n",
            "Iteration 155, loss = 0.00386866\n",
            "Iteration 156, loss = 0.00387643\n",
            "Iteration 157, loss = 0.00387773\n",
            "Iteration 158, loss = 0.00387302\n",
            "Iteration 159, loss = 0.00387289\n",
            "Iteration 160, loss = 0.00384081\n",
            "Iteration 161, loss = 0.00384759\n",
            "Iteration 162, loss = 0.00380416\n",
            "Iteration 163, loss = 0.00380127\n",
            "Iteration 164, loss = 0.00378208\n",
            "Iteration 165, loss = 0.00378683\n",
            "Iteration 166, loss = 0.00377445\n",
            "Iteration 167, loss = 0.00375003\n",
            "Iteration 168, loss = 0.00373296\n",
            "Iteration 169, loss = 0.00374189\n",
            "Iteration 170, loss = 0.00373335\n",
            "Iteration 171, loss = 0.00372299\n",
            "Iteration 172, loss = 0.00374333\n",
            "Iteration 173, loss = 0.00369367\n",
            "Iteration 174, loss = 0.00368922\n",
            "Iteration 175, loss = 0.00366057\n",
            "Iteration 176, loss = 0.00365921\n",
            "Iteration 177, loss = 0.00365369\n",
            "Iteration 178, loss = 0.00361833\n",
            "Iteration 179, loss = 0.00362560\n",
            "Iteration 180, loss = 0.00360686\n",
            "Iteration 181, loss = 0.00359039\n",
            "Iteration 182, loss = 0.00357083\n",
            "Iteration 183, loss = 0.00357915\n",
            "Iteration 184, loss = 0.00355562\n",
            "Iteration 185, loss = 0.00355326\n",
            "Iteration 186, loss = 0.00352794\n",
            "Iteration 187, loss = 0.00352551\n",
            "Iteration 188, loss = 0.00352527\n",
            "Iteration 189, loss = 0.00350490\n",
            "Iteration 190, loss = 0.00350366\n",
            "Iteration 191, loss = 0.00350298\n",
            "Iteration 192, loss = 0.00350402\n",
            "Iteration 193, loss = 0.00350213\n",
            "Iteration 194, loss = 0.00350435\n",
            "Iteration 195, loss = 0.00348905\n",
            "Iteration 196, loss = 0.00346647\n",
            "Iteration 197, loss = 0.00347175\n",
            "Iteration 198, loss = 0.00346302\n",
            "Iteration 199, loss = 0.00344186\n",
            "Iteration 200, loss = 0.00343102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPRegressor(activation='relu', alpha=0.0001, batch_size=64, beta_1=0.9,\n",
              "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "             hidden_layer_sizes=(16, 8, 1), learning_rate='constant',\n",
              "             learning_rate_init=0.01, max_fun=15000, max_iter=200, momentum=0.9,\n",
              "             n_iter_no_change=1000, nesterovs_momentum=True, power_t=0.5,\n",
              "             random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
              "             validation_fraction=0.1, verbose=True, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}